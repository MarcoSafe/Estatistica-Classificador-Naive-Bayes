{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo um filtro de spam utilizando a regra de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, eu vou construir um filtro de spam para mensagens SMS usando o algoritmo multinomial Naive Bayes. O objetivo é escrever um programa que classifique novas mensagens com uma precisão superior a 80%. Dessa forma, espero que mais de 80% das novas mensagens sejam classificadas corretamente como spam ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para treinar o algoritmo, vamos utilizar um conjunto de dados de 5.572 mensagens de SMS que já foram classificadas por humanos. O conjunto de dados foi montado por Tiago A. Almeida e José María Gómez Hidalgo, e pode ser baixado do repositório de Machine Learning da UCI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando o conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou começar importando a biblioteca Pandas e lendo o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam = pd.read_csv(r'C:/Users/msantos/Downloads/SMSSpamCollection.csv', sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sms_spam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, vemos que cerca de 87% das mensagens são de emails que não são spam, ou seja, emails idôneos. Já os 13% restantes são de spam. Esta amostra parece representativa, pois na prática a maioria das mensagens que as pessoas recebem são emails idôneos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de Treinamento e de Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vou dividir o nosso conjunto de dados em um conjunto de treinamento e outro de teste, onde o conjunto de treinamento responderá por 80% dos dados e o conjunto de teste pelos 20% restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)\n",
    "\n",
    "# Training/Test split\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora analisar o percentual de spam e mensagens idôneas nos conjuntos de treinamento e testes. Esperamos que as porcentagens estejam próximas do que temos no conjunto de dados original, onde cerca de 87% das mensagens são de emails idôneos e os 13% restantes são de spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado parece bom. Vamos agora limpar o dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando o Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular todas as probabilidades requeridas pelo algoritmo, primeiro precisamos realizar um pouco de limpeza de dados de modo a trazer os dados em um formato que nos permita extrair facilmente todas as informações que precisamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente, queremos transformar os dados da maneira abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![texte](https://camo.githubusercontent.com/27a4a0a699bd8f0713d73347abe2929c267a03d5/68747470733a2f2f64712d636f6e74656e742e73332e616d617a6f6e6177732e636f6d2f3433332f637067705f646174617365745f332e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letras e Pontuação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover toda e qualquer pontuação e transformas todas as letras para minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before cleaning\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ')\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passemos agora à criação do vocabulário, que neste contexto significa uma lista com todas as palavras únicas em nosso conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que existem 7.783 palavras únicas em todas as mensagens do nosso conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto final de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora usar o vocabulário que acabamos de criar para fazer a transformação de dados que queremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reverse</th>\n",
       "      <th>ffffffffff</th>\n",
       "      <th>fancy</th>\n",
       "      <th>independence</th>\n",
       "      <th>compromised</th>\n",
       "      <th>refunded</th>\n",
       "      <th>non</th>\n",
       "      <th>polo</th>\n",
       "      <th>dignity</th>\n",
       "      <th>bet</th>\n",
       "      <th>...</th>\n",
       "      <th>shrek</th>\n",
       "      <th>flat</th>\n",
       "      <th>tbs</th>\n",
       "      <th>punish</th>\n",
       "      <th>meow</th>\n",
       "      <th>poyyarikatur</th>\n",
       "      <th>analysis</th>\n",
       "      <th>2814032</th>\n",
       "      <th>junna</th>\n",
       "      <th>tonsolitusaswell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reverse  ffffffffff  fancy  independence  compromised  refunded  non  polo  \\\n",
       "0        0           0      0             0            0         0    0     0   \n",
       "1        0           0      0             0            0         0    0     0   \n",
       "2        0           0      0             0            0         0    0     0   \n",
       "3        0           0      0             0            0         0    0     0   \n",
       "4        0           0      0             0            0         0    0     0   \n",
       "\n",
       "   dignity  bet  ...  shrek  flat  tbs  punish  meow  poyyarikatur  analysis  \\\n",
       "0        0    0  ...      0     0    0       0     0             0         0   \n",
       "1        0    0  ...      0     0    0       0     0             0         0   \n",
       "2        0    0  ...      0     0    0       0     0             0         0   \n",
       "3        0    0  ...      0     0    0       0     0             0         0   \n",
       "4        0    0  ...      0     0    0       0     0             0         0   \n",
       "\n",
       "   2814032  junna  tonsolitusaswell  \n",
       "0        0      0                 0  \n",
       "1        0      0                 0  \n",
       "2        0      0                 0  \n",
       "3        0      0                 0  \n",
       "4        0      0                 0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>reverse</th>\n",
       "      <th>ffffffffff</th>\n",
       "      <th>fancy</th>\n",
       "      <th>independence</th>\n",
       "      <th>compromised</th>\n",
       "      <th>refunded</th>\n",
       "      <th>non</th>\n",
       "      <th>polo</th>\n",
       "      <th>...</th>\n",
       "      <th>shrek</th>\n",
       "      <th>flat</th>\n",
       "      <th>tbs</th>\n",
       "      <th>punish</th>\n",
       "      <th>meow</th>\n",
       "      <th>poyyarikatur</th>\n",
       "      <th>analysis</th>\n",
       "      <th>2814032</th>\n",
       "      <th>junna</th>\n",
       "      <th>tonsolitusaswell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  reverse  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]        0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...        0   \n",
       "2   ham                    [welp, apparently, he, retired]        0   \n",
       "3   ham                                           [havent]        0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...        0   \n",
       "\n",
       "   ffffffffff  fancy  independence  compromised  refunded  non  polo  ...  \\\n",
       "0           0      0             0            0         0    0     0  ...   \n",
       "1           0      0             0            0         0    0     0  ...   \n",
       "2           0      0             0            0         0    0     0  ...   \n",
       "3           0      0             0            0         0    0     0  ...   \n",
       "4           0      0             0            0         0    0     0  ...   \n",
       "\n",
       "   shrek  flat  tbs  punish  meow  poyyarikatur  analysis  2814032  junna  \\\n",
       "0      0     0    0       0     0             0         0        0      0   \n",
       "1      0     0    0       0     0             0         0        0      0   \n",
       "2      0     0    0       0     0             0         0        0      0   \n",
       "3      0     0    0       0     0             0         0        0      0   \n",
       "4      0     0    0       0     0             0         0        0      0   \n",
       "\n",
       "   tonsolitusaswell  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando as constantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já terminamos de limpar o conjunto de treinamento e podemos começar a criar o filtro de spam. O algoritmo Naive Bayes terá de responder a estas duas questões de probabilidade para poder classificar novas mensagens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![texte](https://render.githubusercontent.com/render/math?math=P%28Spam%20%7C%20w_1%2Cw_2%2C%20...%2C%20w_n%29%20%5Cpropto%20P%28Spam%29%20%5Ccdot%20%5Cprod_%7Bi%3D1%7D%5E%7Bn%7DP%28w_i%7CSpam%29&mode=display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![texte](https://render.githubusercontent.com/render/math?math=P%28Ham%20%7C%20w_1%2Cw_2%2C%20...%2C%20w_n%29%20%5Cpropto%20P%28Ham%29%20%5Ccdot%20%5Cprod_%7Bi%3D1%7D%5E%7Bn%7DP%28w_i%7CHam%29&mode=display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, para calcular P(wi|Spam) e P(wi|Ham) dentro das fórmulas acima, vamos precisar usar as equações abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![texte](https://render.githubusercontent.com/render/math?math=P%28w_i%7CSpam%29%20%3D%20%5Cfrac%7BN_%7Bw_i%7CSpam%7D%20%2B%20%5Calpha%7D%7BN_%7BSpam%7D%20%2B%20%5Calpha%20%5Ccdot%20N_%7BVocabulary%7D%7D&mode=display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![texte](https://render.githubusercontent.com/render/math?math=P%28w_i%7CHam%29%20%3D%20%5Cfrac%7BN_%7Bw_i%7CHam%7D%20%2B%20%5Calpha%7D%7BN_%7BHam%7D%20%2B%20%5Calpha%20%5Ccdot%20N_%7BVocabulary%7D%7D&mode=display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns dos termos nas quatro equações acima terão o mesmo valor para cada nova mensagem. Podemos calcular o valor desses termos uma vez e evitar fazer os cálculos novamente quando uma nova mensagem chegar. Abaixo, vamos usar o nosso conjunto de treinamento para calcular:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Spam) and P(Ham)\n",
    "- $N_{Spam}$, $N_{Ham}$, $N_{Vocabulary}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também utilizaremos a suavização de Laplace e configurá-la como a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os termos constantes calculados acima, podemos prosseguir com o cálculo dos parâmetros $P(w_i|Spam)$ e $P(w_i|Ham)$. Cada parâmetro será assim um valor de probabilidade condicional associado a cada palavra do vocabulário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os parâmetros são calculados utilizando as fórmulas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![texte](https://render.githubusercontent.com/render/math?math=P%28w_i%7CSpam%29%20%3D%20%5Cfrac%7BN_%7Bw_i%7CSpam%7D%20%2B%20%5Calpha%7D%7BN_%7BSpam%7D%20%2B%20%5Calpha%20%5Ccdot%20N_%7BVocabulary%7D%7D&mode=display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![texte](https://render.githubusercontent.com/render/math?math=P%28w_i%7CHam%29%20%3D%20%5Cfrac%7BN_%7Bw_i%7CHam%7D%20%2B%20%5Calpha%7D%7BN_%7BHam%7D%20%2B%20%5Calpha%20%5Ccdot%20N_%7BVocabulary%7D%7D&mode=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()   # spam_messages already defined in a cell above\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()   # ham_messages already defined in a cell above\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificando uma nova mensagem recebida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos todos os nossos parâmetros calculados, podemos começar a criar o filtro de spam. O filtro de spam pode ser entendido como uma função que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recebe como entrada uma nova mensagem (w1, w2, ..., wn).\n",
    "- Calcula P(Spam|w1, w2, ..., wn) e P(Ham|w1, w2, ..., wn).\n",
    "- Compara os valores de P(Spam|w1, w2, ..., wn) e P(Ham|w1, w2, ..., wn), e:\n",
    "    - Se P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), então a mensagem é classificada como presunto.\n",
    "    - Se P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), então a mensagem é classificada como spam.\n",
    "    - Se P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), então o algoritmo pode solicitar ajuda humana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medição da Precisão do Filtro de Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dois resultados acima parecem promissores, mas vamos ver como o filtro se sai bem no nosso conjunto de teste, que tem 1.114 mensagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar por escrever uma função que devolve as etiquetas de classificação em vez de as imprimir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):    \n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos uma função que devolve etiquetas em vez de as imprimir, podemos usá-la para criar uma nova coluna no nosso conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos escrever uma função para medir a precisão do nosso filtro de spam para descobrir o quão bem o nosso filtro de spam funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "    \n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precisão é próxima de 98,74%, o que é realmente bom. Nosso filtro de spam olhou 1.114 mensagens que não viu em treinamento, e classificou 1.100 corretamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
